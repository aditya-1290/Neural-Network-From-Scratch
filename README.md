# Neural Networks from Scratch

This repository implements neural networks and deep learning concepts from first principles using only NumPy and Matplotlib. No high-level frameworks like TensorFlow or PyTorch are used for the core implementations.

## Philosophy

- **From First Principles**: Every algorithm is implemented from scratch to understand the underlying mathematics.
- **Modular & Educational**: Each file is self-contained and demonstrates a single concept.
- **Progressive Complexity**: Start with simple concepts and build up to advanced architectures.

## Learning Path

1. **01_neurons_and_activation_functions**: Basic building blocks
2. **02_loss_functions**: How to measure model performance
3. **03_gradient_descent**: Optimization algorithms
4. **04_building_a_network**: Combining layers into networks
5. **05_putting_it_all_together**: Training complete models
6. **06_improving_training**: Advanced training techniques
7. **07_convolutional_neural_networks**: CNNs for vision tasks
8. **08_recurrent_neural_networks**: RNNs for sequential data
9. **09_modern_architectures**: Transformers, autoencoders, etc.
10. **10_applications_and_transfer_learning**: Practical applications

## Requirements

Install dependencies:
```bash
pip install -r requirements.txt
```

## Why from Scratch?

Implementing from scratch provides:
- Deep understanding of the mathematics
- Ability to customize and experiment
- Foundation for advanced research
- Appreciation for the engineering in high-level libraries

## Testing

Each implementation should be tested against reference implementations from established libraries to ensure correctness.
